{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXWOUZNM8G_4"
   },
   "source": [
    "# ColaboratoryによるGPU環境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z76Mq7398LrF"
   },
   "source": [
    "## データのダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ynlXVd_Ts3t"
   },
   "source": [
    "以下のコマンドを実行してサンプルプログラムのzipファイル（RL_Book.zip）をダウンロードできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10013,
     "status": "ok",
     "timestamp": 1563967850481,
     "user": {
      "displayName": "伊藤多一",
      "photoUrl": "",
      "userId": "08282946552878127950"
     },
     "user_tz": -540
    },
    "id": "SG_JXetftalp",
    "outputId": "05b1fe31-5690-49d4-a2c3-40f8cc392808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-24 11:30:41--  https://www.shoeisha.co.jp/static/book/download/9784798159928/RL_Book.zip\n",
      "Resolving www.shoeisha.co.jp (www.shoeisha.co.jp)... 114.31.94.139\n",
      "Connecting to www.shoeisha.co.jp (www.shoeisha.co.jp)|114.31.94.139|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14623479 (14M) [application/zip]\n",
      "Saving to: ‘RL_Book.zip’\n",
      "\n",
      "RL_Book.zip         100%[===================>]  13.95M  5.00MB/s    in 2.8s    \n",
      "\n",
      "2019-07-24 11:30:49 (5.00 MB/s) - ‘RL_Book.zip’ saved [14623479/14623479]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.shoeisha.co.jp/static/book/download/9784798159928/RL_Book.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOp7kEqhhXni"
   },
   "source": [
    "## 使用法\n",
    "\n",
    "コンテンツの実行は、当該コンテンツのディレクトリに移動してから行ってください。\n",
    "\n",
    "例1：4-3節のpendulumの学習\n",
    "```shell\n",
    "%cd /content/RL_Book/contents/4-3_ac_pendulum\n",
    "!python3 train.py\n",
    "```\n",
    "予測制御を実行する際は、最初に !xvfb-run -s \"-screen 0 1280x720x24\" を付与して predict.py を実行してください\n",
    "\n",
    "例2：4-3節のpendulumの予測制御\n",
    "```shell\n",
    "!xvfb-run -s \"-screen 0 1280x720x24\" python3 predict.py {weightのパス}\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSq-4N88G8a7"
   },
   "source": [
    "## 環境準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKGvQgq78HQG"
   },
   "source": [
    "### ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 289209,
     "status": "ok",
     "timestamp": 1563968168541,
     "user": {
      "displayName": "伊藤多一",
      "photoUrl": "",
      "userId": "08282946552878127950"
     },
     "user_tz": -540
    },
    "id": "w2c6y9UsoP05",
    "outputId": "5588eea4-989d-4e33-b641-13b541e0af9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  RL_Book.zip\n",
      "   creating: RL_Book/\n",
      "   creating: RL_Book/contents/\n",
      "   creating: RL_Book/contents/2_dp_officeworker/\n",
      "  inflating: RL_Book/contents/2_dp_officeworker/policy_iteration.py  \n",
      "  inflating: RL_Book/contents/2_dp_officeworker/value_iteration.py  \n",
      "   creating: RL_Book/contents/3_keras_example/\n",
      "  inflating: RL_Book/contents/3_keras_example/movie_comment_sample.csv  \n",
      "  inflating: RL_Book/contents/3_keras_example/simple_lstm.py  \n",
      "  inflating: RL_Book/contents/3_keras_example/simple_mnist_cnn.py  \n",
      "  inflating: RL_Book/contents/3_keras_example/simple_mnist_dense.py  \n",
      "  inflating: RL_Book/contents/3_keras_example/simple_rnn.py  \n",
      "   creating: RL_Book/contents/4-2_dqn_pendulum/\n",
      "   creating: RL_Book/contents/4-2_dqn_pendulum/agent/\n",
      "  inflating: RL_Book/contents/4-2_dqn_pendulum/agent/model.py  \n",
      "  inflating: RL_Book/contents/4-2_dqn_pendulum/agent/policy.py  \n",
      "  inflating: RL_Book/contents/4-2_dqn_pendulum/predict.py  \n",
      "   creating: RL_Book/contents/4-2_dqn_pendulum/result/\n",
      "   creating: RL_Book/contents/4-2_dqn_pendulum/result/pendulum/\n",
      "   creating: RL_Book/contents/4-2_dqn_pendulum/result/pendulum/201902201257/\n",
      "  inflating: RL_Book/contents/4-2_dqn_pendulum/result/pendulum/201902201257/episode_100.h5  \n",
      "  inflating: RL_Book/contents/4-2_dqn_pendulum/train.py  \n",
      "  inflating: RL_Book/contents/4-2_dqn_pendulum/util.py  \n",
      "   creating: RL_Book/contents/4-3_ac_pendulum/\n",
      "   creating: RL_Book/contents/4-3_ac_pendulum/agent/\n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/agent/actor.py  \n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/agent/critic.py  \n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/predict.py  \n",
      "   creating: RL_Book/contents/4-3_ac_pendulum/result/\n",
      "   creating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/\n",
      "   creating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/batch_40000/\n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/batch_40000.h5  \n",
      "   creating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/batch_40000/movie_sample/\n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/batch_40000/movie_sample/openaigym.video.0.393.video000010.mp4  \n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/history.csv  \n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/history.png  \n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/result/20190531_071034/options.csv  \n",
      "  inflating: RL_Book/contents/4-3_ac_pendulum/train.py  \n",
      "   creating: RL_Book/contents/5_walker2d/\n",
      "  inflating: RL_Book/contents/5_walker2d/README.md  \n",
      "   creating: RL_Book/contents/5_walker2d/result/\n",
      "   creating: RL_Book/contents/5_walker2d/result/ant/\n",
      "  inflating: RL_Book/contents/5_walker2d/result/ant/episode_500000.h5  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/ant/history.png  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/ant/openaigym.video.0.28867.video000003.mp4  \n",
      "   creating: RL_Book/contents/5_walker2d/result/hopper/\n",
      "  inflating: RL_Book/contents/5_walker2d/result/hopper/episode_500000.h5  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/hopper/history.png  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/hopper/openaigym.video.0.25375.video000002.mp4  \n",
      "   creating: RL_Book/contents/5_walker2d/result/pendulum/\n",
      "  inflating: RL_Book/contents/5_walker2d/result/pendulum/episode_100000.h5  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/pendulum/history.png  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/pendulum/openaigym.video.0.6669.video000004.mp4  \n",
      "   creating: RL_Book/contents/5_walker2d/result/walker2d/\n",
      "  inflating: RL_Book/contents/5_walker2d/result/walker2d/episode_500000.h5  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/walker2d/history.png  \n",
      "  inflating: RL_Book/contents/5_walker2d/result/walker2d/openaigym.video.0.34390.video000001.mp4  \n",
      "   creating: RL_Book/contents/5_walker2d/src/\n",
      "   creating: RL_Book/contents/5_walker2d/src/agent/\n",
      "  inflating: RL_Book/contents/5_walker2d/src/agent/policy_estimator.py  \n",
      "  inflating: RL_Book/contents/5_walker2d/src/agent/value_estimator.py  \n",
      "  inflating: RL_Book/contents/5_walker2d/src/predict.py  \n",
      "  inflating: RL_Book/contents/5_walker2d/src/train.py  \n",
      "  inflating: RL_Book/contents/5_walker2d/src/walk_randomly.py  \n",
      "  inflating: RL_Book/contents/5_walker2d/src/walk_randomly_movie.py  \n",
      "   creating: RL_Book/contents/6-2_tsp/\n",
      "   creating: RL_Book/contents/6-2_tsp/agent/\n",
      "  inflating: RL_Book/contents/6-2_tsp/agent/actor_critic_agent.py  \n",
      "  inflating: RL_Book/contents/6-2_tsp/agent/losses.py  \n",
      "  inflating: RL_Book/contents/6-2_tsp/agent/models.py  \n",
      "   creating: RL_Book/contents/6-2_tsp/gym_env/\n",
      "  inflating: RL_Book/contents/6-2_tsp/gym_env/tsp_env.py  \n",
      "  inflating: RL_Book/contents/6-2_tsp/plot.py  \n",
      "   creating: RL_Book/contents/6-2_tsp/result_sample/\n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/checkpoint  \n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/cmd_memo.txt  \n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/model.059200--2.944-0.06156.ckpt.data-00000-of-00001  \n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/model.059200--2.944-0.06156.ckpt.index  \n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/model.059200--2.944-0.06156.ckpt.meta  \n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/plot.png  \n",
      "  inflating: RL_Book/contents/6-2_tsp/result_sample/reward_log.csv  \n",
      "  inflating: RL_Book/contents/6-2_tsp/test.py  \n",
      "  inflating: RL_Book/contents/6-2_tsp/train.py  \n",
      "   creating: RL_Book/contents/6-2_tsp/util/\n",
      "  inflating: RL_Book/contents/6-2_tsp/util/visualize.py  \n",
      "   creating: RL_Book/contents/6-3_rubiks_cube/\n",
      "   creating: RL_Book/contents/6-3_rubiks_cube/agent/\n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/agent/actor_critic_agent.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/agent/losses.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/agent/memory.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/agent/models.py  \n",
      "   creating: RL_Book/contents/6-3_rubiks_cube/gym_env/\n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/gym_env/cube_algorithm.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/gym_env/rubiks_cube_env.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/plot.py  \n",
      "   creating: RL_Book/contents/6-3_rubiks_cube/result_sample/\n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/checkpoint  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/cmd_memo.txt  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/model.099800-0.394-2.65370.ckpt.data-00000-of-00001  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/model.099800-0.394-2.65370.ckpt.index  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/model.099800-0.394-2.65370.ckpt.meta  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/plot.png  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/result_sample/reward_log.csv  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/test.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/train.py  \n",
      "   creating: RL_Book/contents/6-3_rubiks_cube/util/\n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/util/mcts.py  \n",
      "  inflating: RL_Book/contents/6-3_rubiks_cube/util/visualize.py  \n",
      "   creating: RL_Book/contents/7-1_seqgan/\n",
      "  inflating: RL_Book/contents/7-1_seqgan/agent.py  \n",
      "   creating: RL_Book/contents/7-1_seqgan/data/\n",
      "  inflating: RL_Book/contents/7-1_seqgan/datagenerator.py  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data/input.txt  \n",
      "   creating: RL_Book/contents/7-1_seqgan/data_output_sample/\n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/adversarial_10_generated_sentences.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/adversarial_10_id_generated_sentences.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/generated_sentences.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/id_generated_sentences.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/id_input.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/pre_generated_sentences.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/data_output_sample/pre_id_generated_sentences.txt  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/environment.py  \n",
      "  inflating: RL_Book/contents/7-1_seqgan/main.py  \n",
      "   creating: RL_Book/contents/7-2_enas/\n",
      "  inflating: RL_Book/contents/7-2_enas/agent.py  \n",
      "  inflating: RL_Book/contents/7-2_enas/environment.py  \n",
      "  inflating: RL_Book/contents/7-2_enas/LICENSE.md  \n",
      "  inflating: RL_Book/contents/7-2_enas/main.py  \n",
      "  inflating: RL_Book/contents/7-2_enas/notebook.ipynb  \n",
      "  inflating: RL_Book/contents/7-2_enas/utils.py  \n",
      "  inflating: RL_Book/demo.ipynb      \n",
      "   creating: RL_Book/docker/\n",
      "  inflating: RL_Book/docker/Dockerfile  \n",
      "  inflating: RL_Book/docker/requirements.txt  \n",
      "  inflating: RL_Book/README.md       \n",
      "  inflating: RL_Book/run_docker.sh   \n",
      "/content/RL_Book\n",
      "Collecting matplotlib==3.0.1 (from -r docker/requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f8/4aba1144dad8c67db060049d1a8bc740ad9fa35288d21b82bb85de69ff15/matplotlib-3.0.1-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
      "\u001b[K     |████████████████████████████████| 12.9MB 3.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 3)) (2.8.0)\n",
      "Requirement already satisfied: pydot-ng==2.0.0 in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 4)) (2.0.0)\n",
      "Collecting tqdm==4.30.0 (from -r docker/requirements.txt (line 5))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/4c/103a4d3415dafc1ddfe6a6624333971756e2d3dd8c6dc0f520152855f040/tqdm-4.30.0-py2.py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 26.1MB/s \n",
      "\u001b[?25hCollecting numpy==1.16.2 (from -r docker/requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 43.3MB/s \n",
      "\u001b[?25hCollecting pandas==0.23.4 (from -r docker/requirements.txt (line 7))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl (8.9MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9MB 35.0MB/s \n",
      "\u001b[?25hCollecting pillow==5.3.0 (from -r docker/requirements.txt (line 8))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 33.7MB/s \n",
      "\u001b[?25hCollecting ortools==6.10.6025 (from -r docker/requirements.txt (line 9))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/13/8c8d0fe23da0767ec0f8d00ad14619a20bc6d55ca49a3bd13700e629a1be/ortools-6.10.6025-cp36-cp36m-manylinux1_x86_64.whl (23.7MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7MB 1.4MB/s \n",
      "\u001b[?25hCollecting gym==0.13.1 (from -r docker/requirements.txt (line 10))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/38/87aefd5388f6062267384b7e8f97dbc27c54b3e6137a5148b43d5c10890c/gym-0.13.1.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 46.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from -r docker/requirements.txt (line 11)) (2.2.4)\n",
      "Collecting pyvirtualdisplay==0.2.3 (from -r docker/requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/6b/4bc5678b5219edba7190ae45a7e3d02b03dc7d20ffae84047c7494b355c3/PyVirtualDisplay-0.2.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r docker/requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r docker/requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r docker/requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r docker/requirements.txt (line 1)) (2.5.3)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->-r docker/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.8.0->-r docker/requirements.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4->-r docker/requirements.txt (line 7)) (2018.9)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from ortools==6.10.6025->-r docker/requirements.txt (line 9)) (3.7.1)\n",
      "Collecting pyglet<=1.3.2,>=1.2.0 (from gym==0.13.1->-r docker/requirements.txt (line 10))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 35.9MB/s \n",
      "\u001b[?25hCollecting cloudpickle~=1.2.0 (from gym==0.13.1->-r docker/requirements.txt (line 10))\n",
      "  Downloading https://files.pythonhosted.org/packages/09/f4/4a080c349c1680a2086196fcf0286a65931708156f39568ed7051e42ff6a/cloudpickle-1.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->-r docker/requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->-r docker/requirements.txt (line 11)) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->-r docker/requirements.txt (line 11)) (1.0.8)\n",
      "Collecting EasyProcess (from pyvirtualdisplay==0.2.3->-r docker/requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/29/40040d1d64a224a5e44df9572794a66494618ffe5c77199214aeceedb8a7/EasyProcess-0.2.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.0.1->-r docker/requirements.txt (line 1)) (41.0.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.13.1->-r docker/requirements.txt (line 10)) (0.16.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/14/8e/b4f5c72600f654312b40c0844d4c23f146f291c48ac7a5df62\n",
      "Successfully built gym\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, matplotlib, tqdm, pandas, pillow, ortools, pyglet, cloudpickle, gym, EasyProcess, pyvirtualdisplay\n",
      "  Found existing installation: numpy 1.16.4\n",
      "    Uninstalling numpy-1.16.4:\n",
      "      Successfully uninstalled numpy-1.16.4\n",
      "  Found existing installation: matplotlib 3.0.3\n",
      "    Uninstalling matplotlib-3.0.3:\n",
      "      Successfully uninstalled matplotlib-3.0.3\n",
      "  Found existing installation: tqdm 4.28.1\n",
      "    Uninstalling tqdm-4.28.1:\n",
      "      Successfully uninstalled tqdm-4.28.1\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "  Found existing installation: Pillow 4.3.0\n",
      "    Uninstalling Pillow-4.3.0:\n",
      "      Successfully uninstalled Pillow-4.3.0\n",
      "  Found existing installation: pyglet 1.4.1\n",
      "    Uninstalling pyglet-1.4.1:\n",
      "      Successfully uninstalled pyglet-1.4.1\n",
      "  Found existing installation: cloudpickle 0.6.1\n",
      "    Uninstalling cloudpickle-0.6.1:\n",
      "      Successfully uninstalled cloudpickle-0.6.1\n",
      "  Found existing installation: gym 0.10.11\n",
      "    Uninstalling gym-0.10.11:\n",
      "      Successfully uninstalled gym-0.10.11\n",
      "Successfully installed EasyProcess-0.2.7 cloudpickle-1.2.1 gym-0.13.1 matplotlib-3.0.1 numpy-1.16.2 ortools-6.10.6025 pandas-0.23.4 pillow-5.3.0 pyglet-1.3.2 pyvirtualdisplay-0.2.3 tqdm-4.30.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL",
         "cloudpickle",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "pandas",
         "tqdm"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pybullet-gym'...\n",
      "remote: Enumerating objects: 720, done.\u001b[K\n",
      "remote: Total 720 (delta 0), reused 0 (delta 0), pack-reused 720\u001b[K\n",
      "Receiving objects: 100% (720/720), 19.29 MiB | 28.54 MiB/s, done.\n",
      "Resolving deltas: 100% (397/397), done.\n",
      "/content/RL_Book/pybullet-gym\n",
      "Obtaining file:///content/RL_Book/pybullet-gym\n",
      "Collecting pybullet>=1.7.8 (from pybulletgym==0.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/08/4a032cfb64aa921cab71f9f17b461a682b6238696eb10df38bd4e639ec87/pybullet-2.5.3.tar.gz (50.3MB)\n",
      "\u001b[K     |████████████████████████████████| 50.3MB 1.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pybullet\n",
      "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/de/1b/8fa857253e821dd1046b656582acb2d0716927cc0c821b18de\n",
      "Successfully built pybullet\n",
      "Installing collected packages: pybullet, pybulletgym\n",
      "  Running setup.py develop for pybulletgym\n",
      "Successfully installed pybullet-2.5.3 pybulletgym\n",
      "/content/RL_Book\n",
      "Requirement already satisfied: pyglet in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet) (0.16.0)\n",
      "Requirement already satisfied: pyopengl in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
      "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.3)\n",
      "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.2.7)\n"
     ]
    }
   ],
   "source": [
    "!unzip RL_Book.zip\n",
    "%cd ./RL_Book/\n",
    "!pip install -r docker/requirements.txt\n",
    "!git clone https://github.com/benelot/pybullet-gym\n",
    "%cd pybullet-gym\n",
    "!pip install -e .\n",
    "%cd ..\n",
    "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
    "!pip install pyglet\n",
    "!pip install pyopengl\n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNxD5WsKlelf"
   },
   "source": [
    "**※ライブラリのインストール時にエラーが出る事がありますが、本書のコードを実行する分には問題ありません。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vyPJjgWMeRP"
   },
   "source": [
    "### ランタイムの再起動（必須）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0EVT17mPxuZ"
   },
   "source": [
    "**【重要】ここで、以下の手順にしたがいランタイムを再起動してください。**\n",
    "\n",
    "1. メニューバーの「ランタイム」をクリックしてプルダウンリストを開く。\n",
    "2. プルダウンリストの「ランタイムを再起動...」をクリックする。\n",
    "3. 「ランタイムを再起動」というウィンドウが開くので、そのウィンドウの右下にある「はい」をクリックする。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqGKtmrPqXor"
   },
   "source": [
    "### 動画再生用の関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrrWsuuLqZ09"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def play_movie(mp4_path):\n",
    "  video = io.open(mp4_path, 'r+b').read()\n",
    "  encoded = base64.b64encode(video)\n",
    "  return HTML(data='''<video alt=\"test\" controls>\n",
    "                      <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                      </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDCh8TZjMXH1"
   },
   "source": [
    "## サンプルコードの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yv7WRPWgHHZ3"
   },
   "source": [
    "### コンテンツ一覧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVSTIe-YyR_P"
   },
   "outputs": [],
   "source": [
    "%cd ./RL_Book/\n",
    "%ls contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "We-NNctY9xMn"
   },
   "source": [
    "## 2章　動的計画法（会社員のMDP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFYAkzutauQ3"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/2_dp_officeworker/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aw0IGaZo1EBI"
   },
   "source": [
    "方策反復法による解法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaXLc6mkLoBY"
   },
   "outputs": [],
   "source": [
    "!python3 policy_iteration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-aOtD6yG1EBP"
   },
   "source": [
    "価値反復法による解法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3c-3-jxLoPs"
   },
   "outputs": [],
   "source": [
    " !python3 value_iteration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysCDV22K93sW"
   },
   "source": [
    "## 3章　深層学習（画像分類、文書分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8xf4rGia87X"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/3_keras_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JRvuk2sG1EBg"
   },
   "source": [
    "### 3.1節　多層パーセプトロン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wojgVdHG2sUT"
   },
   "source": [
    "ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjmcFam9yan6"
   },
   "outputs": [],
   "source": [
    "!python3 simple_mnist_dense.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KKNfGzf2xOY"
   },
   "source": [
    "学習済みネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wo0Aoup92yxc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from IPython.display import Image, display\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "(_, _), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "model = load_model(\"simple_mnist_dense_weight.h5\")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "print('入力画像:')\n",
    "imshow(x_test[0], 'gray')\n",
    "plt.show()\n",
    "print(\"予測結果: {}\".format(np.argmax(pred[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qv3TA-ef1EBp"
   },
   "source": [
    "### 3.2節　畳み込み二ューラルネットワーク（CNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jfj8D_2R5UuV"
   },
   "source": [
    "CNNの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTelepEA0bzS"
   },
   "outputs": [],
   "source": [
    "!python3 simple_mnist_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-jLVm8r5d2b"
   },
   "source": [
    "学習済みCNNによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gT7uYZYV5kTp"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"simple_mnist_cnn_weight.h5\")\n",
    "pred = model.predict(x_test.reshape(-1, 28, 28, 1))\n",
    "\n",
    "print('入力画像:')\n",
    "imshow(x_test[0], 'gray')\n",
    "\n",
    "plt.show()\n",
    "print(\"予測結果: {}\".format(np.argmax(pred[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XN7OkLIF1EB5"
   },
   "source": [
    "### 3.3節　再帰型ニューラルネットワーク（RNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJ7ZvztZ9zdF"
   },
   "source": [
    "#### データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XY3J5BDT92l6"
   },
   "outputs": [],
   "source": [
    "!cat \"movie_comment_sample.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dhz5gYVJ1EB7"
   },
   "source": [
    "#### SimpleRNNの学習と予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7llW5N9c-ERr"
   },
   "source": [
    "SimpleRNNの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTcJr2vKyi55"
   },
   "outputs": [],
   "source": [
    "!python3 simple_rnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9r1ByJvCIqt"
   },
   "source": [
    "予測のための関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbmK1xdDCLrn"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 10\n",
    "max_length = 4\n",
    "\n",
    "def load_movie_comment_data():\n",
    "    docs = csv.reader(open(\"movie_comment_sample.csv\"))\n",
    "    next(docs, None)\n",
    "    docs = list(docs)\n",
    "    texts = [d[0] for d in docs]\n",
    "    labels = [int(d[1]) for d in docs]\n",
    "    return texts, labels\n",
    "\n",
    "def preprocessing(texts, labels):\n",
    "    tokenizer = Tokenizer(vocab_size)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    encoded_docs = tokenizer.texts_to_sequences(texts)\n",
    "    padded_docs = pad_sequences(\n",
    "        encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "    train_padded_docs = padded_docs[:6]\n",
    "    test_padded_docs = padded_docs[6:7]\n",
    "\n",
    "    train_labels = labels[:6]\n",
    "    test_labels = labels[6:7]\n",
    "    return train_padded_docs, test_padded_docs, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGYf5VL0-LIz"
   },
   "source": [
    "学習済みSimpleRNNによるポジネガ予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3qonSl1-MvQ"
   },
   "outputs": [],
   "source": [
    "texts, labels = load_movie_comment_data()\n",
    "train_padded_docs, test_padded_docs, train_labels, test_labels = preprocessing(texts, labels)\n",
    "model = load_model(\"simple_rnn_weight.h5\")\n",
    "preds = np.round(model.predict(test_padded_docs))\n",
    "\n",
    "print('入力文: {}'.format(texts[6]))\n",
    "print('id列に変換: {}'.format(test_padded_docs))\n",
    "\n",
    "if preds == 0:\n",
    "    print(\"予測結果: ネガティブ\")\n",
    "else:\n",
    "    print(\"予測結果: ポジティブ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vG03rhD01ECG"
   },
   "source": [
    "#### LSTMの学習と予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEDU3d2f-aIg"
   },
   "source": [
    "LSTMの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkuiM1Kd95Ce"
   },
   "outputs": [],
   "source": [
    "!python3 simple_lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRsrIDlg-3kK"
   },
   "source": [
    "学習済みLSTMによるポジネガ予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTgWf2J8--_Z"
   },
   "outputs": [],
   "source": [
    "texts, labels = load_movie_comment_data()\n",
    "train_padded_docs, test_padded_docs, train_labels, test_labels = preprocessing(texts, labels)\n",
    "model = load_model(\"simple_lstm_weight.h5\")\n",
    "preds = np.round(model.predict(test_padded_docs))\n",
    "\n",
    "print('入力文: {}'.format(texts[6]))\n",
    "print('id列に変換: {}'.format(test_padded_docs))\n",
    "\n",
    "if preds == 0:\n",
    "    print(\"予測結果: ネガティブ\")\n",
    "else:\n",
    "    print(\"予測結果: ポジティブ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIW46mGFW62p"
   },
   "source": [
    "## 4章　深層強化学習（倒立振子制御）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwvQnCHK1ECb"
   },
   "source": [
    "### 4.1節　OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-3ZqOTO1ECd"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pendulum-v0')\n",
    "env.reset()\n",
    "for i in range(3):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "    print(\"action:{}, state:{}, reward:{}\".format(action, state, reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKJ0EzzfgGq_"
   },
   "source": [
    "### 4.2節　Deep Q-Networkによる制御"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BQE_D1PaaUr"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/4-2_dqn_pendulum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oQmZ0paW7DS"
   },
   "outputs": [],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OMpHqJpPLY6"
   },
   "source": [
    "学習結果を使った予測制御  \n",
    "※予測動画を保存するため、xvfb-runというコマンドを先につけて実行する  \n",
    "!xvfb-run -s \"-screen 0 1280x720x24\" python3 predict.py {weightのパス}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQPtslwH4xca"
   },
   "outputs": [],
   "source": [
    "!xvfb-run -s \"-screen 0 1280x720x24\" python3 predict.py result/pendulum/201907240718/episode_300.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "caKLCm778cFb"
   },
   "source": [
    "生成された動画ファイルを再生  \n",
    "play_movie('{動画ファイルのパス}')  \n",
    "\n",
    "**※以下のコマンドラインでは、参考のためサンプル動画ファイルのパスを指定してあります。  \n",
    "予測結果を再生するには、予測して生成された動画ファイルのパスに書きかえて実行してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjDhD8_f7WGX"
   },
   "outputs": [],
   "source": [
    "# play_movie('result/pendulum/201907240718/movie/openaigym.video.0.1887.video000019.mp4')\n",
    "play_movie('result/pendulum/201902201257/movie_sample/openaigym.video.0.1887.video000019.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xvw-xce9fsPY"
   },
   "source": [
    "### 4.3節　Actor-Critic法による制御"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B784TTIyjWj7"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/4-3_ac_pendulum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZ2wVphQHkCX"
   },
   "outputs": [],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBDyWmqp99OE"
   },
   "source": [
    "学習結果を使った予測制御  \n",
    "!xvfb-run -s \"-screen 0 1280x720x24\" python3 predict.py {weightのパス}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwG__HN21erf"
   },
   "outputs": [],
   "source": [
    "!xvfb-run -s \"-screen 0 1280x720x24\" python3 predict.py result/20190531_071034/batch_40000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRc0BPwj_Yus"
   },
   "source": [
    "生成された動画ファイルを再生  \n",
    "play_movie('{動画ファイルのパス}')  \n",
    "\n",
    "**※以下のコマンドラインでは、参考のためサンプル動画ファイルのパスを指定してあります。  \n",
    "予測結果を再生するには、予測して生成された動画ファイルのパスに書きかえて実行してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fclNTtrB3Lrf"
   },
   "outputs": [],
   "source": [
    "# play_movie('result/20190531_071034/batch_40000/movie/openaigym.video.0.2585.video000006.mp4')\n",
    "play_movie('result/20190531_071034/batch_40000/movie_sample/openaigym.video.0.393.video000010.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cfn42r5W7Oc"
   },
   "source": [
    "## 5章　連続制御問題への応用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1563968851798,
     "user": {
      "displayName": "伊藤多一",
      "photoUrl": "",
      "userId": "08282946552878127950"
     },
     "user_tz": -540
    },
    "id": "lJkP-JIa0P69",
    "outputId": "50bd5338-cbd3-4d1d-a4dc-e2be839220bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/RL_Book/contents/5_walker2d\n"
     ]
    }
   ],
   "source": [
    "%cd /content/RL_Book/contents/5_walker2d/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZibXs0J1EDi"
   },
   "source": [
    "### 5.3節　ランダム制御による2足歩行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFu6J5JT1EDj"
   },
   "source": [
    "ランダム制御による2足歩行（報酬出力のみ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6625,
     "status": "ok",
     "timestamp": 1563967371902,
     "user": {
      "displayName": "伊藤多一",
      "photoUrl": "",
      "userId": "08282946552878127950"
     },
     "user_tz": -540
    },
    "id": "IMbtXEn51EDl",
    "outputId": "4e77d85e-bd14-4220-ea6e-646c249f3b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jul 24 2019 10:53:36\n",
      "current_dir=/usr/local/lib/python3.6/dist-packages/pybullet_envs/bullet\n",
      "WalkerBase::__init__\n",
      "options= \n",
      "argv[0]=\n",
      "reward:  0.36053528327174716\n",
      "reward:  0.7523926476715133\n",
      "reward:  1.0938661472173408\n",
      "reward:  1.2577173322308226\n",
      "reward:  1.254470681142993\n",
      "reward:  1.2950025813974206\n",
      "reward:  1.1339103604885166\n",
      "reward:  1.3271904445253313\n",
      "reward:  1.7319188585010123\n",
      "reward:  2.100848731001315\n",
      "reward:  2.6313084415523917\n",
      "reward:  0.14293264981533865\n",
      "episode done\n"
     ]
    }
   ],
   "source": [
    "!python3 src/walk_randomly.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnAN4XjF1EDq"
   },
   "source": [
    "ランダム制御による2足歩行（動画出力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12135,
     "status": "ok",
     "timestamp": 1563968867780,
     "user": {
      "displayName": "伊藤多一",
      "photoUrl": "",
      "userId": "08282946552878127950"
     },
     "user_tz": -540
    },
    "id": "2zWkAtxp1EDr",
    "outputId": "6b5fd1ec-ba27-4792-95e5-86e10d8558a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jul 24 2019 11:32:00\n",
      "current_dir=/usr/local/lib/python3.6/dist-packages/pybullet_envs/bullet\n",
      "WalkerBase::__init__\n",
      "options= \n",
      "argv[0]=\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=3\n",
      "argv[0] = --unused\n",
      "argv[1] = \n",
      "argv[2] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=VMware, Inc.\n",
      "GL_RENDERER=llvmpipe (LLVM 8.0, 256 bits)\n",
      "GL_VERSION=3.3 (Core Profile) Mesa 19.0.2\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30\n",
      "pthread_getconcurrency()=0\n",
      "Version = 3.3 (Core Profile) Mesa 19.0.2\n",
      "Vendor = VMware, Inc.\n",
      "Renderer = llvmpipe (LLVM 8.0, 256 bits)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = VMware, Inc.\n",
      "ven = VMware, Inc.\n",
      "body_info_(b'floor', b'floor_obj')\n",
      "body_info_(b'link0_1', b'walker2d')\n",
      "reward:  0.6477240648804581\n",
      "reward:  0.915553191275103\n",
      "reward:  1.3289181304746307\n",
      "reward:  2.057751064930926\n",
      "reward:  2.35050193570496\n",
      "reward:  3.2444662427529694\n",
      "reward:  -0.11502881503984108\n",
      "episode done\n",
      "reward:  0.753211487880617\n",
      "reward:  1.093029931191995\n",
      "reward:  0.820573538194003\n",
      "reward:  1.1259534580167383\n",
      "reward:  0.9502371820024564\n",
      "reward:  1.4831528946058825\n",
      "reward:  1.2403020039680996\n",
      "reward:  1.3022798982608947\n",
      "reward:  0.7805212255509104\n",
      "reward:  0.3555291572411079\n",
      "reward:  0.37465439110674204\n",
      "reward:  1.0277288157245492\n",
      "reward:  1.3804107452669996\n",
      "reward:  1.173550625439384\n",
      "reward:  1.03910444455978\n",
      "reward:  0.7327467177223298\n",
      "reward:  -0.08237680525635366\n",
      "reward:  1.189215098458226\n",
      "reward:  1.5718743864606948\n",
      "reward:  2.05863903430145\n",
      "reward:  -0.4943895670759957\n",
      "episode done\n",
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n"
     ]
    }
   ],
   "source": [
    "!xvfb-run -s \"-screen 0 1280x720x24\" python3 src/walk_randomly_movie.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0A00w0Gz20R"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import pybulletgym.envs\n",
    "from gym import wrappers\n",
    "import pybullet as p\n",
    "import os\n",
    "\n",
    "\n",
    "predict_dir = './test'\n",
    "os.makedirs(predict_dir, exist_ok=True)\n",
    "env = gym.make('Walker2DPyBulletEnv-v0')\n",
    "env.render(mode='human')\n",
    "env = wrappers.Monitor(env, predict_dir, force=True,\n",
    "                       video_callable=(lambda ep: ep % 1 == 0))\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AL2iXb-_uXb"
   },
   "source": [
    "生成された動画ファイルを再生  \n",
    "play_movie('test/openaigym.video.0.***.video000002.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1722,
     "status": "ok",
     "timestamp": 1563966343074,
     "user": {
      "displayName": "伊藤多一",
      "photoUrl": "",
      "userId": "08282946552878127950"
     },
     "user_tz": -540
    },
    "id": "5lDN3xfs1EDw",
    "outputId": "afc60e8c-1465-49a5-9607-48fe29b3171b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "                      </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_movie('test/openaigym.video.0.1683.video000002.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T56fGWD91ED3"
   },
   "source": [
    "### 5.4節　ガウス方策とREINFORCEアルゴリズムによる2足歩行制御"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbmKKV2wP37d"
   },
   "source": [
    "本節のプログラムの学習には12時間以上をひつようとします。Docker環境においてノートブック 'demo.ipynb'に本節のコードセルが用意してあります。そちらをご利用ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2pbt54pW7xI"
   },
   "source": [
    "## 6章　組合せ最適化への応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "av0Bq1sIH17Q"
   },
   "source": [
    "### 6.2節　巡回セールスマン問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzBVRtapixVJ"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/6-2_tsp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNSUOpZGOUY4"
   },
   "source": [
    "学習の実行（デフォルト設定は --n_episodes 60000）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pru08dDHzV-Z"
   },
   "outputs": [],
   "source": [
    "!python3 train.py --n_episodes 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fcQNAw4OUY9"
   },
   "source": [
    "学習結果を使った探索（デフォルト設定は --n_episodes 5000）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePr6aqnTjw6V"
   },
   "outputs": [],
   "source": [
    "!python3 test.py --model_path result/model.003500--5.076-0.86379.ckpt --n_episodes 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yax4s2_jOUZA"
   },
   "source": [
    "探索結果の可視化（result/plot.png に出力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oySp_nDmDGo"
   },
   "outputs": [],
   "source": [
    "!python3 plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2oEIIR0H57h"
   },
   "source": [
    "### 6.3節　ルービックキューブ問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-WfxA_kH9wu"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/6-3_rubiks_cube/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pn98Xu2om7gh"
   },
   "source": [
    "学習の実行（デフォルト設定は --n_episodes 150000 --n_steps 15）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1l2gdsA5mQKS"
   },
   "outputs": [],
   "source": [
    "!python3 train.py --n_episodes 5000 --n_steps 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbVzAYz4OUZU"
   },
   "source": [
    "学習結果を使った探索（デフォルト設定は --n_episodes 5000 --n_steps 15）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xb9lylJxmUEo"
   },
   "outputs": [],
   "source": [
    "!python3 test.py --model_path result/model.002800-0.289-12.81857.ckpt --n_episodes 500 --n_steps 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WgiohBFzOUZW"
   },
   "source": [
    "探索結果の可視化（result/plot.png に出力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OGotW82mUPF"
   },
   "outputs": [],
   "source": [
    "!python3 plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3W4KilwaXDmK"
   },
   "source": [
    "## 7章　系列データ生成への応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpByhTcdIDHR"
   },
   "source": [
    "### 7.1節　SeqGANによる文書生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KePkfAeP-kR"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/7-1_seqgan/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTn2Tn73OUZh"
   },
   "source": [
    "seqgan による文書生成器の敵対的学習の実行（デフォルト設定は、g_episodes = 50, adversarial_nums = 10）  \n",
    "最新の学習結果により生成された文書は、data/generated_sentences.txt）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryJr8vfmzbfH"
   },
   "outputs": [],
   "source": [
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0h4WfnXIFem"
   },
   "source": [
    "### 7.2節　ENASによるニューラルネットワークアーキテクチャ探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVk1wI-RQD6G"
   },
   "outputs": [],
   "source": [
    "%cd /content/RL_Book/contents/7-2_enas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1BAY8FgOUZw"
   },
   "source": [
    "以下のコマンドを実行して画像データをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qiWlj0sEOUZx"
   },
   "outputs": [],
   "source": [
    "!curl -O http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0sFdz-1OUZ1"
   },
   "source": [
    "画像データの tar ファイルを解凍して得られたフォルダ VOCdevkit を data と改名します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkqkjhIUOUZ2"
   },
   "outputs": [],
   "source": [
    "!tar -xvf VOCtrainval_11-May-2012.tar\n",
    "%mv VOCdevkit data\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ5E223aN5ha"
   },
   "source": [
    "エポック数を指定してENASを実行（結果は result/test と指定）、学習結果を自動でグラフ化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z24w7fkdzbVJ"
   },
   "outputs": [],
   "source": [
    "!python3 main.py -output_dir=./results/test -num_epochs=10 -image_dir=./data/VOC2012/JPEGImages/ -label_dir=./data/VOC2012/SegmentationClass/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gu99TIwrNhhV"
   },
   "source": [
    "出力結果のテキスト (results/test/stdout.txt) があれば、学習を中断しても以下のコマンドを実行して学習結果をグラフ化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSxF6QqeM4Wd"
   },
   "outputs": [],
   "source": [
    "%mkdir test_visualize\n",
    "%cp results/test/stdout.txt test_visualize/\n",
    "!python3 utils.py -output_dir=./test_visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r83SgKJI93cn"
   },
   "source": [
    "### 7.2節　ENAS探索結果の検証  \n",
    "### ENAS探索で得られたベストアーキテクチャによるセマンティックセグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTTMy_TU9cdU"
   },
   "source": [
    "### 1．画像データの準備  \n",
    "必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBnZezna-Nul"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.layers import (Input, Dense, Conv2D, SeparableConv2D,\n",
    "                          AveragePooling2D, MaxPooling2D, UpSampling2D,\n",
    "                          Activation, concatenate, Reshape)\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDCwNtE3-rQ8"
   },
   "source": [
    "画像データのパス、画像サイズ、クラス数を指定します。また、結果の出力先ディレクトリを指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B484W7CY-lFI"
   },
   "outputs": [],
   "source": [
    "data_path = \"data/VOC2012\"\n",
    "image_size = (128, 128)\n",
    "num_classes = 22\n",
    "input_size = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZUzomlvQb4L"
   },
   "source": [
    "ニューラルネットワークの固定情報（フィルタ数、層数）およびENAS探索で得られたベストアーキテクチャを指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bmeTHcYCQa7W"
   },
   "outputs": [],
   "source": [
    "out_filters = 36\n",
    "num_layers = 12\n",
    "sample_arc = [0, 5, 5, 2, 2, 2, 4, 5, 3, 5, 3, 4]\n",
    "save_root = \"./output/20190425\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oUtlRPERvkO"
   },
   "source": [
    "画像データを訓練用、検証用、テスト用に分けておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQrRmy61-3le"
   },
   "outputs": [],
   "source": [
    "# Get the filenames of training image and label data\n",
    "img_path = os.path.join(data_path + \"/JPEGImages/\")\n",
    "lbl_path = os.path.join(data_path + \"/SegmentationClass/\")\n",
    "\n",
    "# Only use names from lbl_path since not all images are labeled\n",
    "lbl_filename_list = os.listdir(lbl_path)\n",
    "lbl_filename_list.sort()\n",
    "img_filename_list = [lbl_filename.replace(\".png\", \".jpg\") for lbl_filename in lbl_filename_list]\n",
    "\n",
    "# Parameters\n",
    "height = image_size[0]\n",
    "width = image_size[1]\n",
    "category = num_classes\n",
    "\n",
    "# 70% train, 20% validation, 10% test\n",
    "num_images = len(img_filename_list)\n",
    "num_train = int(num_images * 0.7)\n",
    "num_valid = int(num_images * 0.2)\n",
    "num_test = num_images - num_train - num_valid\n",
    "train_img_filename_list = img_filename_list[0:num_train]\n",
    "valid_img_filename_list = img_filename_list[num_train:num_train + num_valid]\n",
    "test_img_filename_list = img_filename_list[num_images - num_test:num_images]\n",
    "train_lbl_filename_list = lbl_filename_list[0:num_train]\n",
    "valid_lbl_filename_list = lbl_filename_list[num_train:num_train + num_valid]\n",
    "test_lbl_filename_list = lbl_filename_list[num_images - num_test:num_images]\n",
    "\n",
    "batch_size = 16\n",
    "train_steps_per_epoch = num_train // batch_size\n",
    "valid_steps_per_epoch = num_valid // batch_size\n",
    "\n",
    "# Open all test images and labels\n",
    "test_images = np.zeros((len(test_img_filename_list), height, width, 3), dtype=\"float32\")\n",
    "test_labels = []\n",
    "for index in range(len(test_img_filename_list)):\n",
    "    test_img = Image.open(os.path.join(img_path, test_img_filename_list[index]))\n",
    "    test_img = np.array(test_img)\n",
    "    test_img = cv2.resize(test_img, (height, width))  # Resize\n",
    "    test_img = test_img / 255.0   # Normalize\n",
    "    test_images[index, :, :, :] = test_img\n",
    "\n",
    "    test_lbl = Image.open(os.path.join(lbl_path, test_lbl_filename_list[index]))\n",
    "    test_lbl = test_lbl.resize((height, width))\n",
    "    test_lbl = np.asarray(test_lbl)\n",
    "    test_labels.append(test_lbl)\n",
    "\n",
    "test_labels = np.asarray(test_labels, dtype=np.uint8)\n",
    "\n",
    "# Change indices which correspond to \"void\" from 255\n",
    "test_labels = np.where(test_labels == 255, 21, test_labels)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Convert to one hot encoding\n",
    "identity = np.identity(category, dtype=np.uint8)\n",
    "test_labels = identity[test_labels]\n",
    "\n",
    "print(\"test_img.shape  = \" + str(test_images.shape))\n",
    "print(\"test_lbl.shape  = \" + str(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTIep2S2hVaH"
   },
   "source": [
    "### 2．画像 Generator の準備  \n",
    "訓練用画像の generator（訓練用プログラムに画像を渡す役割を担う）を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pW-PLQmg-75S"
   },
   "outputs": [],
   "source": [
    "def train_input_generator():\n",
    "    while 1:\n",
    "        train_images = np.zeros((batch_size, height, width, 3), dtype=\"float32\")\n",
    "        train_labels = np.zeros((batch_size, height, width))\n",
    "\n",
    "        shuffled_index = list(range(num_train))\n",
    "        random.shuffle(shuffled_index)\n",
    "        batch_idx = 0\n",
    "\n",
    "        for i in shuffled_index:\n",
    "            # Read training images\n",
    "            train_img = Image.open(os.path.join(img_path, train_img_filename_list[i]))\n",
    "            train_img = np.array(train_img)\n",
    "            train_img = cv2.resize(train_img, (height, width))  # Resize\n",
    "            train_img = train_img / 255.0  # Normalize\n",
    "\n",
    "            # Read training labels\n",
    "            train_lbl = Image.open(os.path.join(lbl_path, train_lbl_filename_list[i]))\n",
    "            train_lbl = train_lbl.resize((height, width))\n",
    "\n",
    "            # Flip\n",
    "            do_flip = random.choice([True, False])\n",
    "            if do_flip:\n",
    "                train_img = cv2.flip(train_img, 1)\n",
    "                train_lbl = train_lbl.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "            # Random Crop\n",
    "            do_random_crop = random.choice([True, False])\n",
    "            if do_random_crop:\n",
    "                x_start = random.randint(0, width/2)\n",
    "                y_start = random.randint(0, height/2)\n",
    "                train_img = train_img[y_start:y_start+int(height/2), x_start:x_start+int(width/2)]\n",
    "                train_img = cv2.resize(train_img, (height, width))\n",
    "                train_lbl = train_lbl.crop((x_start, y_start, x_start+int(width/2), y_start+int(height/2)))\n",
    "                train_lbl = train_lbl.resize((height, width))\n",
    "\n",
    "            train_lbl = np.asarray(train_lbl)\n",
    "            np.set_printoptions(threshold=sys.maxsize)\n",
    "            train_images[batch_idx % batch_size] = train_img\n",
    "            train_labels[batch_idx % batch_size] = train_lbl\n",
    "\n",
    "            batch_idx += 1\n",
    "            if (batch_idx % batch_size) == 0:\n",
    "                train_labels_onehot = np.asarray(train_labels, dtype=np.uint8)\n",
    "                # Change indices which correspond to \"void\" from 255\n",
    "                train_labels_onehot = np.where(train_labels_onehot == 255, 21, train_labels_onehot)\n",
    "                np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "                # Convert to one hot encoding\n",
    "                identity = np.identity(category, dtype=np.uint8)\n",
    "                train_labels_onehot = identity[train_labels_onehot]\n",
    "\n",
    "                yield (np.array(train_images), np.array(train_labels_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hz8FEBV8id4L"
   },
   "source": [
    "検証用画像の generator（訓練用プログラムに画像を渡す役割を担う）を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsOFRztOJwAP"
   },
   "outputs": [],
   "source": [
    "def validation_input_generator():\n",
    "    while 1:\n",
    "        valid_images = np.zeros((batch_size, height, width, 3), dtype=\"float32\")\n",
    "        valid_labels = np.zeros((batch_size, height, width))\n",
    "\n",
    "        shuffled_index = list(range(num_valid))\n",
    "        random.shuffle(shuffled_index)\n",
    "        batch_idx = 0\n",
    "\n",
    "        for i in shuffled_index:\n",
    "            # Read training images\n",
    "            valid_img = Image.open(os.path.join(img_path, valid_img_filename_list[i]))\n",
    "            valid_img = np.array(valid_img)\n",
    "            valid_img = cv2.resize(valid_img, (height, width))  # Resize\n",
    "            valid_img = valid_img / 255.0  # Normalize\n",
    "\n",
    "            # Read training labels\n",
    "            valid_lbl = Image.open(os.path.join(lbl_path, valid_lbl_filename_list[i]))\n",
    "            valid_lbl = valid_lbl.resize((height, width))\n",
    "\n",
    "            valid_lbl = np.asarray(valid_lbl)\n",
    "            np.set_printoptions(threshold=sys.maxsize)\n",
    "            valid_images[batch_idx % batch_size] = valid_img\n",
    "            valid_labels[batch_idx % batch_size] = valid_lbl\n",
    "\n",
    "            batch_idx += 1\n",
    "            if (batch_idx % batch_size) == 0:\n",
    "                valid_labels_onehot = np.asarray(valid_labels, dtype=np.uint8)\n",
    "                # Change indices which correspond to \"void\" from 255\n",
    "                valid_labels_onehot = np.where(valid_labels_onehot == 255, 21, valid_labels_onehot)\n",
    "                np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "                # Convert to one hot encoding\n",
    "                identity = np.identity(category, dtype=np.uint8)\n",
    "                valid_labels_onehot = identity[valid_labels_onehot]\n",
    "\n",
    "                yield (np.array(valid_images), np.array(valid_labels_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyGMZnLpip-V"
   },
   "source": [
    "### 3．ENAS探索結果による深層ネットワーク（ENAS-Net）の構築  \n",
    "ENAS探索のベストアーキテクチャを読み込んで、深層ネットワークを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mbY7wkfSHKV"
   },
   "outputs": [],
   "source": [
    "def enas_facory(\n",
    "        input_size,\n",
    "        out_filters,\n",
    "        num_layers,\n",
    "        sample_arc,\n",
    "        num_classes=22):\n",
    "    \n",
    "    pool_distance = num_layers // 4\n",
    "    pool_layers = [pool_distance - 1, 2 * pool_distance - 1, 3 * pool_distance - 1]\n",
    "\n",
    "    \n",
    "    def conv_branch(x, kernel_size=(3, 3), separable=False, dilation_rate=2, out_filters=36):\n",
    "        x = Conv2D(out_filters, (1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        if separable == False:\n",
    "            x = Conv2D(out_filters, kernel_size, dilation_rate=dilation_rate, padding='same')(x)\n",
    "        else:\n",
    "            x = SeparableConv2D(out_filters, kernel_size, strides=(1, 1), padding='same', \n",
    "                                depth_multiplier=1, use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def pool_branch(x, avg_or_max='max', out_filters=36):\n",
    "        x = Conv2D(out_filters, (1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        if avg_or_max == 'avg':\n",
    "            x = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "        elif avg_or_max == 'max':\n",
    "            x = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown pool {}\".format(avg_or_max))\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def enas_layer(x, out_filters):\n",
    "        enas_layers = []\n",
    "        enas_layers.append(conv_branch(x, (3, 3), separable=False, dilation_rate=1, out_filters=out_filters))\n",
    "        enas_layers.append(conv_branch(x, (3, 3), separable=True, out_filters=out_filters))\n",
    "        enas_layers.append(conv_branch(x, (5, 5), separable=False, dilation_rate=1, out_filters=out_filters))\n",
    "        enas_layers.append(conv_branch(x, (5, 5), separable=True, out_filters=out_filters))\n",
    "        enas_layers.append(pool_branch(x, 'avg', out_filters=out_filters))\n",
    "        enas_layers.append(pool_branch(x, 'max', out_filters=out_filters))\n",
    "        return enas_layers\n",
    "    \n",
    "\n",
    "    # Input placeholder\n",
    "    def build_input_layer(input_size):\n",
    "        return Input(shape=input_size, name='input')\n",
    "\n",
    "    # Encoder layers\n",
    "    layers = []\n",
    "    \n",
    "    \n",
    "    def build_encoding_layers(x):\n",
    "        # Stem convolution\n",
    "        x = Conv2D(out_filters, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        # Encoder layers\n",
    "        for layer_id in range(num_layers):\n",
    "            x = enas_layer(x, out_filters)[sample_arc[layer_id]]\n",
    "            if layer_id in pool_layers:\n",
    "                x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "            layers.append(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    # Decoder layers with long skip connections\n",
    "    def build_decoding_layers(x):\n",
    "        # Decorder layers\n",
    "        for layer_id in reversed(range(num_layers)):\n",
    "            x = enas_layer(x, out_filters)[sample_arc[layer_id]]\n",
    "            if layer_id in pool_layers:\n",
    "                x = UpSampling2D(size=(2, 2))(x)\n",
    "                x = concatenate([x,layers[layer_id - 1]], axis=3)\n",
    "                x = Conv2D(out_filters, (1, 1), padding='same')(x)\n",
    "            layers.append(x)\n",
    "        \n",
    "        # end convolution\n",
    "        x = Conv2D(num_classes, (1, 1), padding='same', activation='softmax')(x)\n",
    "        x = Reshape((input_size[0], input_size[1], num_classes), name='conv-output-reshape')(x)\n",
    "        return x\n",
    "\n",
    "    # 入力と出力を指定してモデルを作成\n",
    "    input_img = build_input_layer(input_size)\n",
    "    encoded = build_encoding_layers(input_img)\n",
    "    decoded = build_decoding_layers(encoded)\n",
    "    model = Model(inputs=input_img, outputs=decoded)\n",
    "\n",
    "    # 損失関数、最適化手法、監視メトリクスの設定    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        #loss='mean_squared_error',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_qzsb9fi1KI"
   },
   "source": [
    "モデル構築とサマリーの書き出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg28hZ3nSTMw"
   },
   "outputs": [],
   "source": [
    "enas_unet = enas_facory(input_size, out_filters, num_layers, sample_arc)\n",
    "enas_unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ec4i44lYi6n3"
   },
   "source": [
    "### 4．ENAS-Net の学習  \n",
    "callback 関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYuNtUoOSXIG"
   },
   "outputs": [],
   "source": [
    "def get_callbacks(save_root):\n",
    "    if not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "    tensorboard_dir = os.path.join(save_root, 'tensorboard')\n",
    "    checkpoint_path = os.path.join(save_root, 'weights.{epoch:02d}-{val_loss:.4f}-{val_acc:.4f}.hdf5')\n",
    "    csv_path = os.path.join(save_root, 'log.csv')\n",
    "    \n",
    "    # TensorBoard\n",
    "    tensorboard = TensorBoard(log_dir=tensorboard_dir)\n",
    "    \n",
    "    # エポックごとの自動セーブ\n",
    "    model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1)\n",
    "    \n",
    "    # Save best model\n",
    "    best_model = ModelCheckpoint(os.path.join(save_root,'best_model_weights.hdf5'), \n",
    "                                 monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # csv結果出力\n",
    "    csv_logger = CSVLogger(filename=csv_path)\n",
    "    \n",
    "    callbacks = [tensorboard, model_checkpoint, csv_logger, best_model]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOlPzSHmjEVz"
   },
   "source": [
    "ENAS探索で得られたベストアーキテクチャの深層ネットワークを学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65JHO_kySfdz"
   },
   "outputs": [],
   "source": [
    "# callback関数の生成\n",
    "callbacks = get_callbacks(save_root)\n",
    "\n",
    "# モデル構築\n",
    "enas_unet = enas_facory(input_size, out_filters, num_layers, sample_arc)\n",
    "\n",
    "# 学習回数（エポック数）を指定（1000回以上が望ましいが、試すだけなら100回で十分）\n",
    "num_epoch = 100\n",
    "\n",
    "# 学習の実行\n",
    "enas_unet.fit_generator(generator=train_input_generator(), steps_per_epoch=train_steps_per_epoch, \n",
    "                        epochs=num_epoch, validation_data=validation_input_generator(), \n",
    "                        validation_steps=valid_steps_per_epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cWjer5ljLzz"
   },
   "source": [
    "### 5．学習済み ENAS-Net によるセマンティックセグメンテーション  \n",
    "学習済みネットワークによるセマンティックセグメンテーションのテストに必要な関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_Fl85jNSrs9"
   },
   "outputs": [],
   "source": [
    "##########\n",
    "# セマンティックセグメンテーションの実施と可視化のための関数\n",
    "##########\n",
    "def plot_test(model, test_img, test_lbl):\n",
    "    X = test_img\n",
    "    Y = test_lbl\n",
    "    num_classes = Y.shape[-1]\n",
    "    predicted = model.predict(X)\n",
    "    \n",
    "    max_class = np.argmax(predicted[0], axis=-1)\n",
    "    y_true = np.argmax(Y[0], axis=-1)\n",
    "    \n",
    "    conj_mat = np.zeros((num_classes, num_classes))\n",
    "    for x in range(X.shape[1]):\n",
    "        for y in range(X.shape[2]):\n",
    "            conj_mat[y_true[x,y], max_class[x,y]] += 1\n",
    "    \n",
    "    # Original image\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(131)\n",
    "    ax.imshow(X[0])\n",
    "    ax.set_title('org image')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Ground truth\n",
    "    ax = fig.add_subplot(132)\n",
    "    ax.imshow(y_true)\n",
    "    ax.set_title('ground truth')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Predicted image\n",
    "    ax = fig.add_subplot(133)\n",
    "    ax.imshow(max_class)\n",
    "    ax.set_title('predicted')\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    return conj_mat\n",
    "\n",
    "##########\n",
    "# セマンティックセグメンテーション実施結果の性能指標を計算する関数\n",
    "##########\n",
    "def calc_metrics(conj_mat):\n",
    "    num_truth = np.sum(conj_mat, axis=1)\n",
    "    num_predict = np.sum(conj_mat, axis=0)\n",
    "\n",
    "    R_met = []\n",
    "    P_met = []\n",
    "    F_met = []\n",
    "    IOU = []\n",
    "    A_met = 0\n",
    "    \n",
    "    for cat in range(conj_mat.shape[0]):\n",
    "        if num_predict[cat] != 0:\n",
    "            p = conj_mat[cat,cat]/num_predict[cat]\n",
    "        else:\n",
    "            p = 0\n",
    "        r = conj_mat[cat,cat]/num_truth[cat]\n",
    "        A_met += conj_mat[cat,cat]\n",
    "        if p + r != 0:\n",
    "            f = 2*p*r/(p+r)\n",
    "        else:\n",
    "            f = 0\n",
    "        P_met.append(p)\n",
    "        R_met.append(r)\n",
    "        F_met.append(f)\n",
    "        IOU.append(f/(2-f))\n",
    "    \n",
    "    A_met /= np.sum(num_truth)\n",
    "    mean_IOU = sum(IOU)/len(IOU)\n",
    "\n",
    "    print(\"Accuracy: \" + str(np.round(A_met*10000,0)/100))\n",
    "    print(\"mean_IOU: \" + str(np.round(mean_IOU*10000,0)/100))\n",
    "    print(\"avg_Precision: \" + str(np.round(10000*np.mean(P_met),0)/100))\n",
    "    print(\"avg_Recall: \" + str(np.round(10000*np.mean(R_met),0)/100))\n",
    "    print(\"avg_F-measure: \" + str(np.round(10000*np.mean(F_met),0)/100))\n",
    "    print(\"Precision: \" + str([np.round(p * 10000,0)/100 for i, p in enumerate(P_met)]))\n",
    "    print(\"Recall: \" + str([np.round(r * 10000,0)/100 for i, r in enumerate(R_met)]))\n",
    "    print(\"F-measure: \" + str([np.round(f * 10000,0)/100 for i, f in enumerate(F_met)]))\n",
    "    print(\"IOU: \" + str([np.round(f * 10000,0)/100 for i, f in enumerate(IOU)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imiLJhWwjXN0"
   },
   "source": [
    "学習結果の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOvv2eNySyab"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "enas_unet.load_weights(os.path.join(save_root, \"best_model_weights.hdf5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtoZMen9jbiJ"
   },
   "source": [
    "ベストアーキテクチャの深層ネットワーク（学習済み）を用いたセマンティックセグメンテーションのテストを実施します。  \n",
    "**※次のセルの実行結果には、VOC2012の画像が表示されます。著作権の都合上、この配布用サンプルからは出力結果を削除しました。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5j7pcsQ_S3Ie"
   },
   "outputs": [],
   "source": [
    "conj_mat = np.zeros((num_classes, num_classes))\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    image = np.array([test_images[i]])\n",
    "    label = np.array([test_labels[i]])\n",
    "    conj_mat += plot_test(enas_unet, image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRym5HAqjg8J"
   },
   "source": [
    "テスト結果のファイル出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7FfcgLPS3gX"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(conj_mat)\n",
    "result.to_csv(os.path.join(save_root, 'result_renew.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0F-TOMnjjF3"
   },
   "source": [
    "性能指標の表示  \n",
    "**※以下の出力のうち、Precision, Recall, F-measureは、22クラスごとの数値が以下の順に並んでいます。**  \n",
    "\n",
    "id\t物体クラス  \n",
    "0\tbackground  \n",
    "1\taeroplane  \n",
    "2\tbicycle  \n",
    "3\tbird  \n",
    "4\tboad  \n",
    "5\tbottle  \n",
    "6\tbus  \n",
    "7\tcar  \n",
    "8\tcat  \n",
    "9\tchair  \n",
    "10\tcow  \n",
    "11\tdining table  \n",
    "12\tdog  \n",
    "13\thorse  \n",
    "14\tmotor bike  \n",
    "15\tperson  \n",
    "16\tpotted plant  \n",
    "17\tsheep  \n",
    "18\tsofa  \n",
    "19\ttrain  \n",
    "20\ttv/monitor  \n",
    "21\t(void)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJZ1eJRrS3tW"
   },
   "outputs": [],
   "source": [
    "calc_metrics(conj_mat)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Colaboratoryによる実行環境",
   "provenance": [
    {
     "file_id": "https://github.com/drlbook-jp/drlbook/blob/master/drlbook_examples.ipynb",
     "timestamp": 1563949885725
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
